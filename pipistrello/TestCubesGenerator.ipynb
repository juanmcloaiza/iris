{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils as ui ##needed to import my iris\n",
    "import iris\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_array(tc,xc,yc,zc):\n",
    "    valmax = 30\n",
    "    valmin = 0\n",
    "    zmin = min(zc.points)\n",
    "    zmax = max(zc.points)\n",
    "\n",
    "    t = (tc.points/(365.*24.))*(2.*np.pi)\n",
    "    x = (xc.points/360.) *(2.*np.pi)\n",
    "    y = (yc.points/360.) *(2.*np.pi)\n",
    "    z = (zc.points - zmax)/(zmax-zmin) \n",
    "    \n",
    "    #temp = (valmax-valmin) * np.einsum('i,j,k,l',1+0.*np.sin(t), np.sin(x), np.cos(y), 1+0.*z)\n",
    "    temp = (valmax-valmin) * np.einsum('i,j,k,l', np.sin(t), np.sin(x), np.cos(y), z)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import iris\n",
    "import numpy as np\n",
    "iris.FUTURE.netcdf_no_unlimited = True\n",
    "\n",
    "#t coordinate in hours: 8760 ~ 1yr\n",
    "def generate_cube(tmin = 1, tmax = 24*7,tsamp = 24*7,\n",
    "                xmin = -179, xmax = 180, xsamp = 360,\n",
    "                ymin = -89, ymax = 89, ysamp = 178,\n",
    "                zmin = 0, zmax = 7000, zsamp = 2):\n",
    "\n",
    "    #Create coordinates:\n",
    "    tco = iris.coords.DimCoord(np.linspace(tmin,tmax,tsamp), standard_name='time', units='hours since 2000-01-01 00:00')\n",
    "    tco.guess_bounds()\n",
    "\n",
    "    xco = iris.coords.DimCoord(np.linspace(xmin,xmax,xsamp), standard_name='longitude', units='degree')\n",
    "    xco.guess_bounds()\n",
    "\n",
    "    yco = iris.coords.DimCoord(np.linspace(ymin,ymax,ysamp), standard_name='latitude', units='degree')\n",
    "    yco.guess_bounds()\n",
    "\n",
    "    zco = iris.coords.DimCoord(np.linspace(zmin,zmax,zsamp), standard_name='height', units='metres')\n",
    "    zco.guess_bounds()\n",
    "\n",
    "    #Create cube:\n",
    "    c1 = iris.cube.Cube(fill_array(tco,xco,yco,zco), standard_name='air_temperature', units='celsius')\n",
    "    c1.add_dim_coord(tco, 0)\n",
    "    c1.add_dim_coord(xco, 1)\n",
    "    c1.add_dim_coord(yco, 2)\n",
    "    c1.add_dim_coord(zco, 3)\n",
    "\n",
    "    cube = c1\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_plot(some_cube):\n",
    "\n",
    "#PLOT\n",
    "#Adapted from http://scitools.org.uk/iris/docs/latest/examples/General/anomaly_log_colouring.html\n",
    "\n",
    "    # Construct a plot title\n",
    "    plot_title = some_cube.name()\n",
    "    \n",
    "\n",
    "\n",
    "    # Create an Axes, specifying the map projection.\n",
    "    plt.axes(projection=ccrs.Mollweide())\n",
    "    #plt.axes(projection=ccrs.Stereographic())\n",
    "\n",
    "    # Make a pseudocolour plot using this colour scheme.\n",
    "    # Use a standard colour map which varies blue-white-red.\n",
    "    # For suitable options, see the 'Diverging colormaps' section in:\n",
    "    # http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    anom_cmap = 'bwr'\n",
    "    mesh = iplt.pcolormesh(some_cube, cmap=anom_cmap)\n",
    "\n",
    "    # Add a colourbar, with extensions to show handling of out-of-range values.\n",
    "    bar = plt.colorbar(mesh, orientation='horizontal', extend='both')\n",
    "\n",
    "    # Set some suitable fixed \"logarithmic\" colourbar tick positions.\n",
    "    #tick_levels = [-3, -2, -1, 0.0, 1, 2, 3]\n",
    "    #bar.set_ticks(tick_levels)\n",
    "\n",
    "    # Modify the tick labels so that the centre one shows \"+/-<minumum-level>\".        \n",
    "    #minimum_level = 0.0\n",
    "    #maximum_level = 30\n",
    "    #tick_levels[3] = r'$\\pm${:g}'.format(minimum_level)\n",
    "    #bar.set_ticklabels(tick_levels)\n",
    "\n",
    "    # Label the colourbar to show the units.\n",
    "    bar.set_label('[{}]'.format(time_mean.units))\n",
    "\n",
    "    # Add coastlines and a title.\n",
    "    plt.gca().coastlines()\n",
    "    plt.title(plot_title)\n",
    "\n",
    "    # Display the result.\n",
    "    iplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST: CALCULATE THE MEAN\n",
    "import cartopy.crs as ccrs\n",
    "import iris.coord_categorisation\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "# Enable a future option, to ensure that the netcdf load works the same way\n",
    "# as in future Iris versions.\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "# Load a sample air temperatures sequence.\n",
    "temperatures = generate_cube(tmin = 24, tmax = 24*7,tsamp = 24*7,\n",
    "                xmin = -170, xmax = 170, xsamp = 36,\n",
    "                ymin = -80, ymax = 80, ysamp = 18,\n",
    "                zmin = 0, zmax = 7000, zsamp = 2)\n",
    "\n",
    "\n",
    "# Calculate the mean:\n",
    "time_mean = temperatures.collapsed(['time','height'], iris.analysis.MEAN)\n",
    "\n",
    "# Plot:\n",
    "my_plot(time_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST CONCATENATION AND THEN MEAN\n",
    "\n",
    "#Each cube will span from t_a[i] to t_b[i] with t_num_samp in between\n",
    "#Total span of the cubes: t_a[0] to t_b[-1]\n",
    "\n",
    "t_a = range(1 , 24*800-23,24)\n",
    "t_b = range(24, 24*800,24)\n",
    "t_num_samp = 24\n",
    "\n",
    "cubes = []\n",
    "for t_init,t_end in zip(t_a,t_b):\n",
    "    #print(t_init,t_end)\n",
    "    cubes.append(generate_cube(tmin = t_init, tmax = t_end,tsamp = t_num_samp,\n",
    "                xmin = -170, xmax = 170, xsamp = 36,\n",
    "                ymin = -80, ymax = 80, ysamp = 18,\n",
    "                zmin = 0, zmax = 7000, zsamp = 2))\n",
    "\n",
    "loaded_cubes = iris.cube.CubeList(cubes)\n",
    "\n",
    "disordered = iris.cube.CubeList([loaded_cubes[6],loaded_cubes[0], loaded_cubes[5],loaded_cubes[1],\n",
    "              loaded_cubes[4],loaded_cubes[2], loaded_cubes[3]])\n",
    "\n",
    "concatenated = disordered.concatenate()\n",
    "print(concatenated)\n",
    "\n",
    "concatenated = loaded_cubes.concatenate()\n",
    "print(concatenated)\n",
    "\n",
    "concat_mean = concatenated[0].collapsed(['time','height'], iris.analysis.MEAN)\n",
    "\n",
    "# Plot:\n",
    "my_plot(concat_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST MEAN AND THEN CONCATENATION\n",
    "\n",
    "#Each cube will span from t_a[i] to t_b[i] with t_num_samp in between\n",
    "#Total span of the cubes: t_a[0] to t_b[-1]\n",
    "\n",
    "t_a = range(1 , 24*800-23,24)\n",
    "t_b = range(24, 24*800,24)\n",
    "t_num_samp = 24\n",
    "\n",
    "cubes = []\n",
    "for t_init,t_end in zip(t_a,t_b):\n",
    "    #print(t_init,t_end)\n",
    "    cubes.append(generate_cube(tmin = t_init, tmax = t_end,tsamp = t_num_samp,\n",
    "                xmin = -170, xmax = 170, xsamp = 36,\n",
    "                ymin = -80, ymax = 80, ysamp = 18,\n",
    "                zmin = 0, zmax = 7000, zsamp = 2).collapsed(['time','height'], iris.analysis.MEAN))\n",
    "\n",
    "loaded_cubes = iris.cube.CubeList(cubes)\n",
    "merged_cubes = loaded_cubes.merge()\n",
    "print(merged_cubes)\n",
    "mean_merge_mean = merged_cubes[0].collapsed(['time','height'], iris.analysis.MEAN)\n",
    "my_plot(mean_merge_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_merge_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(concat_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.save(mean_merge_mean,'./shitload_of_data/mean_merge_mean.nc')\n",
    "iris.save(concat_mean,'./shitload_of_data/concat_mean.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save cubes after applying the mean - This simulates what we have after the map phase\n",
    "\n",
    "#Each cube will span from t_a[i] to t_b[i] with t_num_samp in between\n",
    "#Total span of the cubes: t_a[0] to t_b[-1]\n",
    "\n",
    "t_a = range(1 , 24*701-23,24)\n",
    "t_b = range(24, 24*701,24)\n",
    "t_num_samp = 24\n",
    "\n",
    "cubes = []\n",
    "i=0\n",
    "for t_init,t_end in zip(t_a,t_b):\n",
    "    #print(t_init,t_end)\n",
    "    i += 1\n",
    "    cube = generate_cube(tmin = t_init, tmax = t_end,tsamp = t_num_samp,\n",
    "                xmin = -170, xmax = 170, xsamp = 36,\n",
    "                ymin = -80, ymax = 80, ysamp = 18,\n",
    "                zmin = 0, zmax = 7000, zsamp = 2).collapsed(['time','height'], iris.analysis.MEAN)\n",
    "    iris.save(cube,'./shitload_of_data/mean_cube_'+str(i)+'.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure that all these loads are merged in one single cube:\n",
    "\n",
    "cubes1 = iris.load('./shitload_of_data/mean_cube_1*.nc')\n",
    "cubes2 = iris.load('./shitload_of_data/mean_cube_2*.nc')\n",
    "cubes3 = iris.load('./shitload_of_data/mean_cube_3*.nc')\n",
    "cubes4 = iris.load('./shitload_of_data/mean_cube_4*.nc')\n",
    "cubes5 = iris.load('./shitload_of_data/mean_cube_5*.nc')\n",
    "cubes6 = iris.load('./shitload_of_data/mean_cube_6*.nc')\n",
    "cubes7 = iris.load('./shitload_of_data/mean_cube_7*.nc')\n",
    "cubes8 = iris.load('./shitload_of_data/mean_cube_8*.nc')\n",
    "cubes9 = iris.load('./shitload_of_data/mean_cube_9*.nc')\n",
    "cubes = iris.cube.CubeList(cubes1+cubes2+cubes3+cubes4+cubes5+cubes6+cubes7+cubes8+cubes9)\n",
    "print(\"Not correct:\")\n",
    "print(cubes.concatenate())\n",
    "\n",
    "print(\"Correct:\")\n",
    "slices = []\n",
    "for cube in cubes:\n",
    "    for yx_slice in cube.slices(['latitude', 'longitude']):\n",
    "        slices.append(yx_slice)\n",
    "\n",
    "new_cubes = iris.cube.CubeList(slices)\n",
    "\n",
    "print(new_cubes.merge())\n",
    "iris.save(new_cubes[0],'./shitload_of_data/new_cube.nc')\n",
    "my_plot(new_cubes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10 10\n",
      "300\n",
      "1\n",
      "files saved\n"
     ]
    }
   ],
   "source": [
    "#GENERATE DATA\n",
    "#BE SURE THAT THE DATA IS MERGEABLE:\n",
    "import numpy as np\n",
    "hours_in_a_day = 24\n",
    "n_days = 3\n",
    "\n",
    "#Cubes will be generated in this range:\n",
    "t0_glob = 1\n",
    "tmax_glob = hours_in_a_day * (n_days)\n",
    "dt_glob = 1 * hours_in_a_day\n",
    "\n",
    "#Each single cube will have these number of samples and delta t locally:\n",
    "t_num_samp = 8\n",
    "dt_loc = dt_glob / t_num_samp\n",
    "\n",
    "#These are the arrays which will contain t_init and t_max for each cube\n",
    "t_a = np.arange( t0_glob, tmax_glob - dt_glob + dt_loc,  dt_glob )\n",
    "t_b = np.arange( t0_glob + dt_glob - dt_loc, tmax_glob, dt_glob )\n",
    "\n",
    "#We repeat what we did for the time for the rest of the coordinates:\n",
    "\n",
    "###X\n",
    "x0_glob = -179\n",
    "xmax_glob = 180\n",
    "dx_glob = 35#10\n",
    "\n",
    "x_num_samp = 10\n",
    "dx_loc = dx_glob / x_num_samp\n",
    "\n",
    "x_a = np.arange( x0_glob, xmax_glob - dx_glob + dx_loc,  dx_glob )\n",
    "x_b = np.arange( x0_glob + dx_glob - dx_loc, xmax_glob, dx_glob )\n",
    "\n",
    "###Y\n",
    "y0_glob = -89\n",
    "ymax_glob = 89\n",
    "dy_glob = 17#10\n",
    "\n",
    "y_num_samp = 10\n",
    "dy_loc = dy_glob / y_num_samp\n",
    "\n",
    "y_a = np.arange( y0_glob, ymax_glob - dy_glob + dy_loc,  dy_glob )\n",
    "y_b = np.arange( y0_glob + dy_glob - dy_loc, ymax_glob, dy_glob )\n",
    "\n",
    "\n",
    "cubes = []\n",
    "tcubes = len(t_a)\n",
    "xcubes = len(x_a)\n",
    "ycubes = len(y_a)\n",
    "zcubes = 0\n",
    "for t_init,t_end in zip(t_a,t_b):\n",
    "    \n",
    "    for x_init,x_end in zip(x_a,x_b):\n",
    "    \n",
    "        for y_init,y_end in zip(y_a,y_b):\n",
    "    \n",
    "            cubes.append(generate_cube(tmin = t_init, tmax = t_end,tsamp = t_num_samp,\n",
    "                                       xmin = x_init, xmax = x_end,xsamp = x_num_samp,\n",
    "                                       ymin = y_init, ymax = y_end,ysamp = y_num_samp,\n",
    "                                        zmin = 0, zmax = 7000, zsamp = 2))\n",
    "            \n",
    "print(tcubes,xcubes,ycubes)\n",
    "cubelist = iris.cube.CubeList(cubes)\n",
    "print(len(cubelist))\n",
    "print(len(cubelist.concatenate()))\n",
    "for i in range(len(cubelist)):\n",
    "    iris.save(cubelist[i],\"./shitload_of_data/file_{:03d}.nc\".format(i))\n",
    "print(\"files saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_temperature / (celsius)         (time: 8; longitude: 10; latitude: 10; height: 2)\n",
      "     Dimension coordinates:\n",
      "          time                           x             -             -           -\n",
      "          longitude                      -             x             -           -\n",
      "          latitude                       -             -             x           -\n",
      "          height                         -             -             -           x\n",
      "     Attributes:\n",
      "          Conventions: CF-1.5\n",
      "air_temperature / (celsius)         (longitude: 10; latitude: 10)\n",
      "     Dimension coordinates:\n",
      "          longitude                           x             -\n",
      "          latitude                            -             x\n",
      "     Scalar coordinates:\n",
      "          height: 3500.0 metres, bound=(-3500.0, 10500.0) metres\n",
      "          time: 2000-01-02 11:30:00, bound=(2000-01-01 23:30:00, 2000-01-02 23:30:00)\n",
      "     Attributes:\n",
      "          Conventions: CF-1.5\n",
      "     Cell methods:\n",
      "          mean: height, time\n"
     ]
    }
   ],
   "source": [
    "#MAP PHASE:\n",
    "#BE SURE THAT THE MEAN IS DONE PROPERLY:\n",
    "\n",
    "input_dir = \"./shitload_of_data/\"\n",
    "mapper_output_dir = \"./mapper_output_dir/\"\n",
    "\n",
    "\n",
    "def get_mean_height(hdfs_path,local_path,save_to):\n",
    "    cubes = iris.load(local_path)\n",
    "    mean_height = cubes[0].collapsed(['height','time'], iris.analysis.MEAN)\n",
    "    iris.save(mean_height,save_to)\n",
    "    return\n",
    "\n",
    "#This is done by all nodes in the cluster in parallel:\n",
    "for root,dirs,files in os.walk(input_dir):\n",
    "    for f in files:\n",
    "        hdfs_path = \"/\".join([root,f])\n",
    "        local_path = \"/\".join([root,f])\n",
    "        save_to = mapper_output_dir+\"/\"+\"map_\"+hdfs_path.split(\"/\")[-1].rpartition(\".\")[-3]+\".nc\"\n",
    "        get_mean_height(hdfs_path,local_path,save_to)\n",
    "#        sys.stdout.write(save_to)\n",
    "\n",
    "print(iris.load_cube(hdfs_path))\n",
    "print(iris.load_cube(save_to))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conc:\n",
      "0: air_temperature / (celsius)         (longitude: 100; latitude: 100)\n",
      "1: air_temperature / (celsius)         (longitude: 100; latitude: 100)\n",
      "2: air_temperature / (celsius)         (longitude: 100; latitude: 100)\n",
      "Merged:\n",
      "0: air_temperature / (celsius)         (time: 3; longitude: 100; latitude: 100)\n",
      "taking the mean...\n",
      "saving...\n",
      "./reducer_output_dir/reduce_0.nc\n"
     ]
    }
   ],
   "source": [
    "reducer_output_dir = \"./reducer_output_dir\"\n",
    "\n",
    "def concatenate_and_merge(mapper_output_dir,save_to):\n",
    "\n",
    "    #Load cubes from files inside mapper output dir:\n",
    "    cubes = []\n",
    "    for root,dirs,files in os.walk(mapper_output_dir):\n",
    "        for f in files:\n",
    "            try:\n",
    "                to_load = \"/\".join([root,f])\n",
    "                cubes.append(iris.load_cube(to_load))\n",
    "                \n",
    "            except:\n",
    "                print(\"cube not loaded from {}\".format(to_load))\n",
    "                pass\n",
    "        break\n",
    "\n",
    "    #if no cubes were loaded, stop.\n",
    "    if cubes == []:\n",
    "        print(\"no files found inside {}\".format(mapper_output_dir))\n",
    "        return\n",
    "\n",
    "    #Now we have a cube list with only one value for at least one coordinate:\n",
    "    cube_list = iris.cube.CubeList(cubes)\n",
    "    #print(\"Orig:\")\n",
    "    #print(cube_list)\n",
    "    \n",
    "    #concatenate\n",
    "    concatenated_cubes = cube_list.concatenate()\n",
    "    print(\"Conc:\")\n",
    "    print(concatenated_cubes)\n",
    "\n",
    "    #We need to merge them:\n",
    "    merged_cubes = concatenated_cubes.merge()  \n",
    "    #print(merged_cubes)\n",
    "    print(\"Merged:\")\n",
    "    print(merged_cubes)\n",
    "    \n",
    "    #Take one last time the mean:\n",
    "    print(\"taking the mean...\")\n",
    "    mean_ = merged_cubes[0].collapsed(['time','height'], iris.analysis.MEAN)\n",
    "\n",
    "    print(\"saving...\")\n",
    "    iris.save(mean_,save_to)\n",
    "    return\n",
    "\n",
    "\n",
    "save_to = reducer_output_dir+\"/reduce_0.nc\"\n",
    "    \n",
    "concatenate_and_merge(mapper_output_dir,save_to)\n",
    "\n",
    "sys.stdout.write(save_to)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
